# Changelog

Все значимые изменения в этом проекте будут задокументированы в этом файле.

Формат основан на [Keep a Changelog](https://keepachangelog.com/ru/1.0.0/),
и этот проект придерживается [Semantic Versioning](https://semver.org/lang/ru/).

## [1.8.1] - 2026-01-28

### Добавлено

#### Анализ размера топиков
- `ПолучитьРазмерТопика` / `GetTopicSize` - получение размера топика в байтах:
  - Подсчёт путём чтения всех сообщений из всех партиций
  - Возвращает общий размер, количество сообщений и детализацию по партициям
  - Параметр таймаута для длительных операций (по умолчанию 30000 мс)

#### Настраиваемый таймаут остановки консьюмера
- `УстановитьТаймаутОчисткиКонсьюмера` / `SetConsumerCloseTimeout` - установка таймаута для остановки консьюмера:
  - По умолчанию 10000 мс (10 секунд)
  - Влияет на время ожидания завершения фоновых операций при вызове `ОстановитьКонсьюмера`

### Изменено

#### Улучшенная обработка ошибок в методах остановки
- **`ОстановитьПродюсера` / `StopProducer`** - теперь возвращает `Ложь` в случае ошибки:
  - Таймаут flush - не все сообщения были доставлены за отведённое время
  - Ошибка flush - проблема при очистке очереди сообщений
  - После flush остались недоставленные сообщения (`outq_len() > 0`)
  - Текст ошибки доступен через `ПолучитьСообщениеОбОшибке()`

- **`ОстановитьКонсьюмера` / `StopConsumer`** - теперь возвращает `Ложь` в случае ошибки:
  - Ошибка close - не удалось корректно закрыть подключение консьюмера
  - Таймаут wait_destroyed - фоновые операции не завершились за отведённое время
  - Текст ошибки доступен через `ПолучитьСообщениеОбОшибке()`

### Документация
- Обновлена документация `ОстановитьПродюсера` в [docs/producer.md](./docs/producer.md):
  - Описаны возвращаемые значения и условия возврата `Ложь`
  - Добавлены рекомендации по обработке ошибок
- Обновлена документация `ОстановитьКонсьюмера` в [docs/consumer.md](./docs/consumer.md):
  - Описаны возвращаемые значения и условия возврата `Ложь`
  - Добавлен раздел "Настройка таймаута остановки"
  - Добавлены рекомендации по обработке ошибок

---

## [1.8.0] - 2026-01-26

### Добавлено

#### Schema Registry API
Полная интеграция с Confluent Schema Registry для управления схемами данных:
- `ЗарегистрироватьСхему` / `RegisterSchema` - регистрация новой схемы в Schema Registry
- `ПолучитьСхемуПоИД` / `GetSchemaById` - получение схемы по её идентификатору
- `ПолучитьПоследнююСхему` / `GetLatestSchema` - получение последней версии схемы для subject
- `ПолучитьВерсииСхемы` / `GetSchemaVersions` - получение списка всех версий схемы
- `УдалитьСхему` / `DeleteSchema` - удаление схемы по версии

#### Metrics API
Встроенная система метрик для мониторинга производительности:
- `ПолучитьМетрикиПродюсера` / `GetProducerMetrics` - JSON с метриками продюсера:
  - Количество отправленных сообщений и байт
  - Счётчик ошибок и повторных попыток
  - Время работы и средняя скорость (сообщений/сек, байт/сек)
- `ПолучитьМетрикиКонсьюмера` / `GetConsumerMetrics` - JSON с метриками консьюмера:
  - Количество прочитанных сообщений и байт
  - Счётчик ошибок и таймаутов poll
  - Время работы и средняя скорость
- `СброситьМетрики` / `ResetMetrics` - сброс всех счётчиков метрик

#### Пакетное чтение сообщений
- `ЧитатьПакетСообщений` / `ConsumeBatch` - эффективное пакетное чтение сообщений:
  - Параметр `maxMessages` - максимальное количество сообщений (по умолчанию 100)
  - Параметр `maxWaitMs` - максимальное время ожидания в мс (по умолчанию 1000)
  - Возвращает JSON с массивом сообщений и их количеством
  - Автоматическое обновление метрик консьюмера

#### Кастомизация партиционирования
- `УстановитьПартишионер` / `SetPartitioner` - выбор алгоритма распределения сообщений по партициям:
  - `consistent` - консистентное хеширование
  - `consistent_random` - консистентное хеширование со случайным начальным значением (по умолчанию)
  - `murmur2` - алгоритм MurmurHash2 (совместим с Java клиентом)
  - `murmur2_random` - MurmurHash2 со случайным началом
  - `fnv1a` - алгоритм FNV-1a
  - `fnv1a_random` - FNV-1a со случайным началом
  - `random` - случайное распределение

#### Настраиваемые таймауты
- `УстановитьТаймаутОчисткиПродюсера` / `SetProducerFlushTimeout` - настройка таймаута flush операции (по умолчанию 20000 мс)
- `УстановитьТаймаутАдминОпераций` / `SetAdminOperationTimeout` - настройка таймаута административных операций (по умолчанию 10000 мс)

#### RAII Helper для Admin API
- Внутренний класс `AdminClientScope` для автоматического управления ресурсами Admin API
- Устранение дублирования кода в административных методах
- Гарантированная очистка ресурсов при выходе из области видимости

### Изменено
- **Тип `getMessageTimestamp`**: изменён с `float` на `double` для повышения точности временных меток
- **Структура кода**: заменены все `goto retry` на `while` циклы в методах `produce()`, `produceAvro()`, `produceBatch()`

### Исправлено
- **Утечка памяти в `commitOffset`**: добавлена очистка `TopicPartition*` после использования
- **Опечатки**: исправлено `experemental` → `experimental` в комментариях
- **Комментарий**: исправлено "10 seconds" → "20 seconds" в `produceAvroWithWaitResult`

### Техническая информация
- Добавлена зависимость от CURL для Schema Registry API
- Добавлено ~800 строк нового кода
- 11 новых экспортируемых методов для 1С:
  - 5 методов Schema Registry API
  - 3 метода Metrics API
  - 1 метод пакетного чтения
  - 1 метод настройки партиционера
  - 2 метода настройки таймаутов
- Интеграция метрик в существующие методы `produce()` и `getMessage()`
- Использование `std::atomic` для потокобезопасных счётчиков метрик

### Требования к сборке
- Добавлена зависимость: CURL (для Schema Registry)
- CMakeLists.txt обновлён с `find_package(CURL REQUIRED)` и `target_link_libraries(... CURL::libcurl)`

### Практические применения новых возможностей

**Schema Registry:**
- Централизованное управление схемами Avro/JSON Schema
- Версионирование схем для эволюции данных
- Валидация схем перед отправкой сообщений
- Совместимость с экосистемой Confluent

**Metrics API:**
- Мониторинг производительности в реальном времени
- Диагностика проблем с производительностью
- Интеграция с системами мониторинга
- Оценка пропускной способности

**ConsumeBatch:**
- Эффективная обработка большого потока сообщений
- Снижение накладных расходов на вызовы методов
- Пакетная обработка данных

**SetPartitioner:**
- Оптимизация распределения нагрузки
- Совместимость с Java клиентами (murmur2)
- Контроль над маршрутизацией сообщений

## [1.7.1] - 2026-01-21

### Добавлено
- Метод `ПолучитьВозможностиБиблиотеки` / `GetBuiltinFeatures` - получение информации о доступных возможностях librdkafka:
  - Версия библиотеки librdkafka
  - Список поддерживаемых функций (ssl, gzip, snappy, lz4, zstd, sasl, sasl_plain, sasl_scram и др.)
  - Полезно для диагностики проблем с SSL, сжатием или аутентификацией

### Изменено
- **Документация**: Уточнено описание возвращаемых значений методов отправки сообщений:
  - Асинхронные методы (`ОтправитьСообщение`, `ОтправитьСообщениеAVRO`, `ОтправитьСообщениеProtobuf`) возвращают статус помещения в очередь (0 = успех, -1 = ошибка), а не статус доставки
  - Синхронные методы (`*СОжиданиемРезультата`) возвращают реальный статус доставки (0, 1, 2)
  - Исправлен некорректный пример проверки результата асинхронной отправки
  - Добавлен пример синхронной отправки с проверкой статуса доставки

### Исправлено
- **Критическое**: Исправлено автоматическое создание топиков при запросе метаданных несуществующего топика
  - Методы `ПолучитьМетаданныеТопика` / `GetTopicMetadata`, `ПолучитьГраницыПартиции` / `GetPartitionWatermarks` и `ПолучитьКоличествоСообщенийВПартиции` / `GetPartitionMessageCount` больше не создают топики при обращении к несуществующим топикам
  - Добавлена явная установка параметра `allow.auto.create.topics=false` для временных producer'ов в admin-методах
  - Теперь при обращении к несуществующему топику методы корректно возвращают ошибку вместо автоматического создания топика

## [1.7.0] - 2026-01-06

### Добавлено
- **Consumer Assignment** - явное назначение партиций консьюмеру (manual partition assignment):
  - `НазначитьПартиции` / `Assign` - явное назначение конкретных партиций для чтения консьюмером
  - `ПолучитьНазначение` / `GetAssignment` - получение текущего назначения партиций в формате JSON
  - `ОтменитьНазначение` / `Unassign` - отмена всех назначенных партиций
  - Поддержка установки начального offset для каждой партиции при назначении
  - Альтернатива автоматической подписке через `Подписаться()` для полного контроля над партициями

- **Транзакционная поддержка** (Exactly-Once семантика):
  - `ИнициализироватьТранзакционногоПродюсера` / `InitTransactionalProducer` - инициализация транзакционного продюсера
  - `НачатьТранзакцию` / `BeginTransaction` - начало новой транзакции
  - `ЗафиксироватьТранзакцию` / `CommitTransaction` - фиксация транзакции
  - `ОтменитьТранзакцию` / `AbortTransaction` - откат транзакции
  - `ОтправитьОфсетыВТранзакцию` / `SendOffsetsToTransaction` - сохранение офсетов консьюмера в транзакцию
  - Гарантия атомарной записи множества сообщений
  - Поддержка паттерна Read-Process-Write

- **Пакетная отправка сообщений**:
  - `ОтправитьПакетСообщений` / `ProduceBatch` - эффективная отправка множества сообщений одной операцией
  - Поддержка индивидуальных ключей, партиций и заголовков для каждого сообщения в пакете
  - Минимизация количества обращений к API компоненты

- **Управление группами консьюмеров**:
  - `УдалитьГруппуКонсьюмеров` / `DeleteConsumerGroup` - удаление группы консьюмеров
  - `СброситьОфсетыГруппыКонсьюмеров` / `ResetConsumerGroupOffsets` - сброс офсетов группы на начало, конец или временную метку

- **Методы проверки кластера и брокеров**:
  - `ПроверитьДоступностьБрокера` / `PingBroker` - проверка доступности брокера Kafka (health check)
  - `ПолучитьКоличествоСообщенийВПартиции` / `GetPartitionMessageCount` - получение количества сообщений в партиции

- **Расширенная документация**:
  - Полная документация Consumer Assignment в [docs/consumer.md](./docs/consumer.md)
  - Документация по health check и мониторингу в [docs/admin.md](./docs/admin.md)
  - Примеры использования для всех новых методов на языке 1С
  - Практические сценарии применения явного назначения партиций

### Изменено
- **Реорганизация документации** - методы управления позицией чтения перемещены из admin.md в consumer.md:
  - `ПерейтиКНачалу` / `SeekToBeginning` - переход к началу партиции
  - `ПерейтиККонцу` / `SeekToEnd` - переход к концу партиции
  - `ПерейтиКВременнойМетке` / `SeekToTimestamp` - переход к указанной временной метке
  - Эти методы теперь правильно классифицированы как операции консьюмера, а не административные

### Исправлено
- Тип возвращаемого значения `getPartitionMessageCount` изменен с `int64_t` на `double` для совместимости с `variant_t`
- Все возвращаемые значения `-1` заменены на `-1.0` для соответствия типу `double`
- Добавлен `static_cast<double>()` при возврате результата вычисления количества сообщений

### Техническая информация
- Добавлено 13 новых экспортируемых методов для 1С:
  - 3 метода Consumer Assignment
  - 5 методов транзакционной поддержки
  - 1 метод пакетной отправки
  - 2 метода управления группами консьюмеров
  - 2 метода мониторинга и health check
- Добавлено ~1200 строк кода:
  - ~400 строк для Consumer Assignment
  - ~300 строк для транзакционной поддержки
  - ~200 строк для пакетной отправки
  - ~150 строк для управления группами консьюмеров
  - ~150 строк для ping и подсчета сообщений
- Расширена документация на ~500 строк с практическими примерами
- Consumer Assignment реализован через librdkafka API: `assign()`, `assignment()`, `unassign()`
- Транзакции реализованы через librdkafka transactional API

### Практические применения новых возможностей

**Транзакционная поддержка:**
- Гарантия Exactly-Once для критичных операций (финансы, платежи, заказы)
- Атомарная отправка связанных сообщений (все или ничего)
- Паттерн Read-Process-Write без дубликатов
- Координация между чтением из одного топика и записью в другой

**Пакетная отправка:**
- Эффективная отправка большого количества сообщений
- Снижение накладных расходов на обращения к API
- Массовая загрузка данных в Kafka
- Синхронизация данных между системами

**Consumer Assignment:**
- Обработка конкретных партиций при миграции или восстановлении данных
- Параллельная обработка независимыми консьюмерами без использования consumer groups
- Тестирование обработки данных из конкретных партиций
- Переобработка исторических данных с определенного offset

**Управление группами консьюмеров:**
- Удаление неиспользуемых consumer groups для освобождения ресурсов
- Сброс офсетов для повторной обработки данных
- Восстановление после сбоев в обработке
- Миграция между версиями приложения

**Health Check и мониторинг:**
- Проверка доступности Kafka перед началом работы приложения
- Мониторинг состояния брокеров в кластере
- Автоматический failover при недоступности основного брокера
- Мониторинг объема данных в партициях
- Планирование ресурсов для обработки данных
- Балансировка нагрузки между партициями

## [1.6.1] - 2026-01-05

### Добавлено
- Полная поддержка Protocol Buffers (Protobuf):
  - `СохранитьСхемуProtobuf` / `PutProtoSchema` - сохранение .proto схемы для последующего использования
  - `ПреобразоватьВФорматProtobuf` / `ConvertToProtobufFormat` - конвертация JSON данных в Protobuf формат
  - `СохранитьФайлProtobuf` / `SaveProtobufFile` - сохранение Protobuf данных в файл
  - `ДекодироватьСообщениеProtobuf` / `DecodeProtobufMessage` - декодирование Protobuf сообщений в JSON или бинарные данные
  - `ОтправитьСообщениеProtobuf` / `ProduceProtobuf` - асинхронная отправка Protobuf сообщений в Kafka
  - `ОтправитьСообщениеProtobufСОжиданиемРезультата` / `ProduceProtobufWithWaitResult` - синхронная отправка Protobuf сообщений
- Метод декодирования AVRO сообщений:
  - `ДекодироватьСообщениеAVRO` / `DecodeAvroMessage` - декодирование AVRO сообщений в JSON или бинарные данные
- Реализован метод получения параметров:
  - `ПолучитьПараметры` / `GetParameters` - получение всех установленных через `УстановитьПараметр` параметров в формате JSON
- Документация по статической линковке Protobuf в Visual Studio ([docs/visual_studio_build.md](./docs/visual_studio_build.md))
- Вспомогательные функции для работы с Protobuf:
  - `SetProtobufFieldFromJson` - конвертация JSON значений в поля Protobuf
  - `GetJsonFromProtobufField` - конвертация полей Protobuf в JSON значения
- Функция `convertAvroDatumToJson` для конвертации AVRO данных в JSON

### Исправлено
- **Критическое**: Исправлена кодировка русских имен методов - все методы теперь корректно отображаются в 1С (вместо `�������������������������` теперь `ПолучитьСообщениеОбОшибке`)
- Исправлен конфликт между Windows API макросом `GetMessage` и методом `google::protobuf::Reflection::GetMessage()` путем добавления `#undef GetMessage`
- Исправлены ошибки компиляции под Linux GCC:
  - Явное преобразование `std::string` в `boost::json::value` через `boost::json::string()`
  - Удалены неиспользуемые переменные (warning об unused variable `branch`)
- Улучшена совместимость сборки между Windows MSVC и Linux GCC компиляторами

### Изменено
- Обновлены заголовочные файлы:
  - Добавлены заголовки Protobuf: `google/protobuf/descriptor.h`, `google/protobuf/message.h`, `google/protobuf/dynamic_message.h`, `google/protobuf/compiler/parser.h`, `google/protobuf/io/tokenizer.h`, `google/protobuf/io/zero_copy_stream_impl.h`
- Обновлен `CMakeLists.txt` с настройками для статической линковки Protobuf в Visual Studio
- Улучшена документация по сборке проекта через Visual Studio IDE

### Техническая информация
- Добавлено 636+ строк кода для поддержки Protobuf
- Класс `ProtobufContext` для управления схемами и сообщениями Protobuf
- Поддержка динамического создания Protobuf сообщений на основе .proto схем
- Файл должен быть сохранён в кодировке UTF-8 with BOM для корректного отображения русских символов

## [1.6.0]
### Добавлено
- Admin API функции для управления топиками

## [1.5.3]
### Исправлено
- Различные исправления ошибок

---

[1.8.1]: https://github.com/NuclearAPK/Simple-Kafka_Adapter/compare/v1.8.0...v1.8.1
[1.8.0]: https://github.com/NuclearAPK/Simple-Kafka_Adapter/compare/v1.7.1...v1.8.0
[1.7.1]: https://github.com/NuclearAPK/Simple-Kafka_Adapter/compare/v1.7.0...v1.7.1
[1.7.0]: https://github.com/NuclearAPK/Simple-Kafka_Adapter/compare/v1.6.1...v1.7.0
[1.6.1]: https://github.com/NuclearAPK/Simple-Kafka_Adapter/compare/v1.6.0...v1.6.1
[1.6.0]: https://github.com/NuclearAPK/Simple-Kafka_Adapter/compare/v1.5.3...v1.6.0
[1.5.3]: https://github.com/NuclearAPK/Simple-Kafka_Adapter/releases/tag/v1.5.3
